{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use the MLDL_Project_Template Notebook and `requirements.txt`\n",
    "\n",
    "This notebook provides instructions for using the `ML_Project_Template.ipynb` notebook, which implements an end-to-end Data Science/ML project with traditional ML, AutoML, and deep learning components.\n",
    "\n",
    "## Save the Notebook\n",
    "- Copy the JSON content of `ML_Project_Template.ipynb` into a text editor and save it as `ML_Project_Template.ipynb`.\n",
    "- Alternatively, manually add the Deep Learning section and update the relevant sections (Model Training, Evaluation, Hyperparameter Tuning, Interpretation, Deployment) in your existing notebook.\n",
    "\n",
    "## Save the Updated `requirements.txt`\n",
    "- Copy the updated `requirements.txt` content into a file named `requirements.txt`.\n",
    "- Install the dependencies in a virtual environment:\n",
    "\n",
    "```bash\n",
    "python -m venv env\n",
    "source env/bin/activate  # On Windows: env\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Run the Notebook\n",
    "- Open `ML_Project_Template.ipynb` in Jupyter Notebook or JupyterLab.\n",
    "- Update the project-specific variables (`DATA_PATH`, `TARGET_COLUMN`, `TASK_TYPE`, `MODEL_SAVE_PATH`) as needed.\n",
    "- Execute the cells sequentially. The Deep Learning section will train a neural network, plot training/validation loss, and include the model in the evaluation pipeline.\n",
    "\n",
    "## Customize the Deep Learning Model\n",
    "- Modify the `build_deep_learning_model` function to adjust the neural network architecture (e.g., add more layers, change activation functions, or use different optimizers).\n",
    "- Adjust the `epochs`, `batch_size`, or `patience` in `train_deep_learning_model` for your dataset.\n",
    "- For multi-class classification, update the output layer in `build_deep_learning_model` to use `Dense(n_classes, activation='softmax')` and `loss='categorical_crossentropy'`, and ensure `y_train` is one-hot encoded.\n",
    "\n",
    "## Test with a Sample Dataset\n",
    "- If you donâ€™t have a dataset, use a sample from `sklearn.datasets` (e.g., `load_iris` for classification or `load_diabetes` for regression) to test the notebook:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "DATA_PATH = None  # Set to None since we're loading directly\n",
    "TARGET_COLUMN = 'target'\n",
    "TASK_TYPE = 'classification'\n",
    "```\n",
    "\n",
    "## Notes\n",
    "- **Deep Learning Model**: The neural network is a simple feedforward network with two hidden layers and dropout for regularization. Customize the architecture (e.g., add convolutional layers for image data or LSTM for time series) based on your dataset.\n",
    "- **Classification Assumption**: The deep learning section assumes binary classification for simplicity. For multi-class tasks, modify the output layer and loss function as noted above.\n",
    "- **SHAP for Deep Learning**: The `shap.DeepExplainer` is used for the Keras model. Note that SHAP computation for neural networks can be slow for large datasets; consider sampling `X_train` if needed.\n",
    "- **Hardware Requirements**: Deep learning models may require significant computational resources. If available, use a GPU to speed up training by ensuring TensorFlow is configured for GPU support (`tensorflow-gpu`).\n",
    "- **TensorFlow Version**: The `requirements.txt` specifies `tensorflow==2.15.0`, which is stable and widely compatible. If you need GPU support, install `tensorflow-gpu` instead or adjust the version based on your hardware.\n",
    "- **AutoML and Deep Learning**: The AutoML section (FLAML) and deep learning section are complementary. FLAML may include neural networks in its search, but the explicit deep learning section allows for custom architectures and training.\n",
    "\n",
    "## Testing and Troubleshooting\n",
    "- **Test the Notebook**: Use a small dataset initially to ensure all sections run correctly. Increase the `time_budget` in AutoML or `epochs` in deep learning for larger datasets.\n",
    "- **Memory Issues**: If you encounter memory issues with deep learning or SHAP, reduce the dataset size, batch size, or use a smaller neural network.\n",
    "- **Dependencies**: Ensure all packages in `requirements.txt` are installed. If conflicts arise, try installing `tensorflow` separately or use a newer/older version (e.g., `tensorflow==2.16.0`).\n",
    "\n",
    "## Next Steps\n",
    "- Contact support if you need help customizing the deep learning model (e.g., for specific tasks like image classification or time series), integrating with a particular dataset, or adding other deep learning frameworks (e.g., PyTorch).\n",
    "- **Learn about Keras**: Explore the [Keras documentation](https://keras.io/) for advanced model architectures, custom layers, and training techniques.\n",
    "- **Explore PyTorch**: Check out the [PyTorch documentation](https://pytorch.org/) for flexible deep learning workflows, especially for research-oriented tasks or dynamic computation graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
